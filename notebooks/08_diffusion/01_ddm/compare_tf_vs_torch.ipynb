{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare sinusiodal embeddings results between tensorflow and torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models,activations\n",
    "\n",
    "import torch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=6.9077554>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.math.log(tf.constant(1000.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "DATASET_REPETITIONS = 5\n",
    "LOAD_MODEL = False\n",
    "\n",
    "NOISE_EMBEDDING_SIZE = 32\n",
    "PLOT_DIFFUSION_STEPS = 20\n",
    "\n",
    "# optimization\n",
    "EMA = 0.999\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_embedding(x):\n",
    "    frequencies = tf.exp(\n",
    "        tf.linspace(\n",
    "            tf.math.log(1.0),\n",
    "            tf.math.log(1000.0),\n",
    "            NOISE_EMBEDDING_SIZE // 2,\n",
    "        )\n",
    "    )\n",
    "    angular_speeds = 2.0 * math.pi * frequencies\n",
    "    embeddings = tf.concat(\n",
    "        [tf.sin(angular_speeds * x), tf.cos(angular_speeds * x)], axis=3\n",
    "    )\n",
    "    return embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define simple model that will accept an input with shape (1,1,1) and apply sinusoidal embedding function on it\n",
    "noise_variances = layers.Input(shape=(1,1,1))\n",
    "noise_embedding = layers.Lambda(sinusoidal_embedding)(noise_variances)\n",
    "model = models.Model(noise_variances,noise_embedding, name=\"sin_emb\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = tf.constant(0.34,shape=(1,1,1))\n",
    "y = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf emb shape : (1, 1, 1, 32)\n",
      "tf sin emb output :\n",
      "[[[[ 8.4432781e-01 -2.4176864e-01 -7.9383200e-01  7.9565132e-01\n",
      "     7.9113644e-01  5.8778441e-01  6.4400035e-01 -2.5121161e-01\n",
      "    -2.2208980e-01  2.9371348e-01  2.5971909e-05 -6.5481865e-01\n",
      "     5.6658745e-01  7.8468496e-01 -1.5987124e-01  1.9868393e-04\n",
      "    -5.3582692e-01 -9.7033393e-01  6.0813713e-01 -6.0575485e-01\n",
      "     6.1163974e-01 -8.0901760e-01 -7.6502520e-01 -9.6793216e-01\n",
      "    -9.7502619e-01 -9.5589352e-01  1.0000000e+00  7.5578606e-01\n",
      "    -8.2400167e-01 -6.1989480e-01 -9.8713785e-01  1.0000000e+00]]]]\n"
     ]
    }
   ],
   "source": [
    "print(f\"tf emb shape : {y.shape}\")\n",
    "print(f\"tf sin emb output :\\n{y}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sinusoidal_embedding_torch(x:torch.tensor):\n",
    "    frequencies = torch.exp(torch.linspace(torch.log(torch.tensor(1.0)),torch.log(torch.tensor(1000.0)),NOISE_EMBEDDING_SIZE//2))\n",
    "    angular_speeds = 2 * torch.pi* frequencies * x\n",
    "    return torch.cat((torch.sin(angular_speeds), torch.cos(angular_speeds)), dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 32])\n"
     ]
    }
   ],
   "source": [
    "x_torch = torch.tensor([[0.34]])\n",
    "y_torch = sinusoidal_embedding_torch(x_torch)\n",
    "print(y_torch.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 8.4433e-01, -2.4177e-01, -7.9383e-01,  7.9565e-01,  7.9114e-01,\n",
       "          5.8778e-01,  6.4400e-01, -2.5121e-01, -2.2209e-01,  2.9371e-01,\n",
       "          2.5972e-05, -6.5482e-01,  5.6659e-01,  7.8442e-01, -1.5987e-01,\n",
       "          1.9868e-04, -5.3583e-01, -9.7033e-01,  6.0814e-01, -6.0575e-01,\n",
       "          6.1164e-01, -8.0902e-01, -7.6503e-01, -9.6793e-01, -9.7503e-01,\n",
       "         -9.5589e-01,  1.0000e+00,  7.5579e-01, -8.2400e-01, -6.2023e-01,\n",
       "         -9.8714e-01,  1.0000e+00]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalEmbedding(nn.Module):\n",
    "    def __init__(self, device, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.device = device\n",
    "        frequencies = torch.linspace(torch.log(torch.tensor(1.0)),torch.log(torch.tensor(1000.0)),16)\n",
    "        frequencies = frequencies.unsqueeze(0).unsqueeze(2).unsqueeze(3)\n",
    "        frequencies = frequencies.to(device)\n",
    "        self.frequencies = frequencies\n",
    "    \n",
    "    def forward(self,x):\n",
    "        angular_speeds = 2 * torch.pi * torch.exp(self.frequencies) * x\n",
    "        # return single scalar as 32 dimensional vector\n",
    "        return torch.cat((torch.sin(angular_speeds),torch.cos(angular_speeds)),dim=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "device = torch.device('cpu')\n",
    "sinemb_model = SinusoidalEmbedding(device=device)\n",
    "out = sinemb_model(x_torch)\n",
    "print(out.shape)\n",
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "x_torch = torch.tensor([[0.34]])\n",
    "print(x_torch.requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Conv2d between tf and torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "width = 5\n",
    "theinput = layers.Input(shape=(5,5,3))\n",
    "residual = layers.Conv2D(width, kernel_size=1)(theinput)\n",
    "model = models.Model(theinput, residual,name=\"conv2d\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate tensor with normal distribution and save it to a file and load it from a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x194011ef070>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "tftensor = tf.random.normal(shape=(5,5,3))\n",
    "nptensor = tftensor.numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "tempfolder = pathlib.Path.cwd()/\"temp_files\"\n",
    "filename=\"nptensor00.npy\"\n",
    "np.save(str(tempfolder/filename),nptensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "loadednptensor=np.load(str(tempfolder/filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# checking that loaded tensor and original tensor are equal\n",
    "print((nptensor==loadednptensor).sum()==5*5*3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded tf tensor shape : (5, 5, 3)\n"
     ]
    }
   ],
   "source": [
    "loadedtftensor=tf.convert_to_tensor(loadednptensor)\n",
    "print(f\"loaded tf tensor shape : {loadedtftensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "out shape : (1, 5, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# now pass it through a model\n",
    "out = model(tf.expand_dims(loadedtftensor,axis=0))\n",
    "print(f\"out shape : {out.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's try the same with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class SimpleModel(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels,kernel_size=1)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        return self.conv(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch tensor shape : torch.Size([1, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "torch_tensor = torch.from_numpy(loadednptensor)\n",
    "torch_tensor = torch_tensor.permute(2,0,1).unsqueeze(0)\n",
    "print(f\"torch tensor shape : {torch_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_model = SimpleModel(3,width)\n",
    "torch_out = torch_model(torch_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 5, 5])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(5,), dtype=float32, numpy=\n",
       "array([-0.74220693, -0.7008943 ,  0.59093624, -0.2729187 , -0.04410662],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0,0,0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.3840,  0.7626, -0.1298, -0.7966,  0.3099],\n",
       "       grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out[0,:,0,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "second layer weights list length :  2\n",
      "first param shape :  (1, 1, 3, 5)\n",
      "second param shape :  (5,)\n"
     ]
    }
   ],
   "source": [
    "print(\"second layer weights list length : \",len(model.layers[1].get_weights()))\n",
    "\n",
    "# convolution filters have the shape FHxFWxFCxFN, where FH is filter height, FW is filter width, FC is filter channels which usually matches input tensors channels\n",
    "# FN is the number of filters which will translate to output channels\n",
    "print(\"first param shape : \",model.layers[1].get_weights()[0].shape)\n",
    "print(\"second param shape : \",model.layers[1].get_weights()[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "[[[ 0.40754956  0.83004147 -0.5517646 ]]]\n"
     ]
    }
   ],
   "source": [
    "tf_conv_filters=model.layers[1].get_weights()[0]\n",
    "tf_conv_filters_bias = model.layers[1].get_weights()[1]\n",
    "print(type(tf_conv_filters))\n",
    "print(tf_conv_filters[:,:,:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I want to manually set the parameters of nn.Conv2D\n",
    "tc_filters = torch.from_numpy(tf_conv_filters)\n",
    "tc_filters = tc_filters.permute(3,2,0,1)\n",
    "tc_filt_biases = torch.from_numpy(tf_conv_filters_bias)\n",
    "\n",
    "with torch.no_grad():\n",
    "    torch_model.conv.weight.copy_(tc_filters)\n",
    "    torch_model.conv.bias.copy_(tc_filt_biases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "torch_params=[param for param in torch_model.parameters()]\n",
    "print(len(torch_params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "first param shape :  torch.Size([5, 3, 1, 1])\n",
      "second param shape :  torch.Size([5])\n"
     ]
    }
   ],
   "source": [
    "print(\"first param shape : \",torch_params[0].shape)\n",
    "print(\"second param shape : \",torch_params[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tc_out shape : torch.Size([1, 5, 5, 5]), tf out shape : (1, 5, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# now I want to pass x to conv2D with new weights and compare the results with that of tensorflow conv2d\n",
    "tc_out = torch_model(torch_tensor)\n",
    "print(f\"tc_out shape : {tc_out.shape}, tf out shape : {out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch out first channel output tensor([[[-0.7422, -1.9824, -0.7168, -0.9868, -1.4923],\n",
      "         [ 1.6791,  0.7415, -1.3628, -0.6151,  0.5614],\n",
      "         [ 0.2119,  0.5652,  0.9435, -1.8063,  0.5516],\n",
      "         [ 0.2992, -0.1099, -0.5495, -0.5857,  0.9035],\n",
      "         [ 0.6210,  0.6236, -1.5218,  1.4500,  1.4976]]],\n",
      "       grad_fn=<SliceBackward0>)\n",
      "tf first channel output : [[[-0.74220693 -1.9824156  -0.7168442  -0.98682624 -1.4923443 ]\n",
      "  [ 1.6790966   0.74148107 -1.3627936  -0.61512125  0.5614329 ]\n",
      "  [ 0.21191429  0.5651724   0.94349176 -1.806262    0.5516483 ]\n",
      "  [ 0.29922476 -0.10988607 -0.54947203 -0.58572084  0.90354264]\n",
      "  [ 0.6210349   0.62357324 -1.5217959   1.4499993   1.49762   ]]]\n"
     ]
    }
   ],
   "source": [
    "print(\"torch out first channel output\", tc_out[:,0,:,:])\n",
    "print(f\"tf first channel output : {out[:,:,:,0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's compare BatchNormalization between tensorflow and torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 5, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "# let us generate random N,W,H,C tensor, pass it through convolution and save the result\n",
    "tf_x=tf.random.normal(shape=(10,5,5,3))\n",
    "tf_out = model(tf_x)\n",
    "print(tf_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename=\"nptensor01.npy\"\n",
    "np.save(str(tempfolder/filename), tf_out.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_bn_input = layers.Input(shape=(5,5,5))\n",
    "tf_batch_norm = layers.BatchNormalization(center=False, scale=False)(tf_bn_input)\n",
    "bn_model = models.Model(tf_bn_input, tf_batch_norm, name=\"batch_norm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf batch normalization output shape :  (10, 5, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "tf_bn_out=bn_model(tf_out,training=True)\n",
    "print(\"tf batch normalization output shape : \",tf_bn_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([-0.888895   -0.7787231   0.5411658  -0.06579003 -0.0377686 ], shape=(5,), dtype=float32)\n",
      "tf.Tensor([-0.8884508  -0.77833396  0.5408954  -0.06575715 -0.03774973], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(tf_out[0,0,0,:])\n",
    "print(tf_bn_out[0,0,0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf mean shape :  (5, 5, 5)\n",
      "tf variances shape :  (5, 5, 5)\n"
     ]
    }
   ],
   "source": [
    "tf_means = tf.reduce_mean(tf_out,axis=0)\n",
    "tf_vars = tf.math.reduce_variance(tf_out,axis=0)\n",
    "print(\"tf mean shape : \",tf_means.shape)\n",
    "print(\"tf variances shape : \", tf_vars.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of first feature across batches :  tf.Tensor(-0.43894997, shape=(), dtype=float32)\n",
      "variance of first feature across batches :  tf.Tensor(1.7402786, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"mean of first feature across batches : \",tf_means[0,0,0])\n",
    "print(\"variance of first feature across batches : \",tf_vars[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean of first feature calculated with numpy across batches :  -0.43895\n",
      "variance of first feature calculated with numpy across batches :  1.740278363456028\n"
     ]
    }
   ],
   "source": [
    "# with this I am confirming the behavior of tf.reduce_mean and tf.math.reduce_variance\n",
    "print(\"mean of first feature calculated with numpy across batches : \",tf_out.numpy()[:,0,0,0].mean())\n",
    "print(\"variance of first feature calculated with numpy across batches : \",tf_out.numpy()[:,0,0,0].std()**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(10,), dtype=float32, numpy=\n",
       "array([-0.34107512,  0.34862122,  0.36523625, -0.4958102 ,  1.689387  ,\n",
       "        1.3150597 ,  0.57471246, -1.3216718 , -0.5958357 , -1.5386238 ],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(tf_out[:,0,0,0]-tf_means[0,0,0])/tf.math.sqrt(tf_vars[0,0,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "manual mean : [-0.07195345 -0.05061551  0.11001837 -0.02935027  0.06918108], manual variance : [1.1207141  0.73636943 0.88828963 0.8977073  0.66772294]\n",
      "tf bn mean : <tf.Variable 'batch_normalization/moving_mean:0' shape=(5,) dtype=float32, numpy=\n",
      "array([-0.00071953, -0.00050616,  0.00110018, -0.0002935 ,  0.00069181],\n",
      "      dtype=float32)>, tf bn variance : <tf.Variable 'batch_normalization/moving_variance:0' shape=(5,) dtype=float32, numpy=\n",
      "array([1.0012522 , 0.99739325, 0.9989186 , 0.9990131 , 0.99670404],\n",
      "      dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "# I couldn't verify how tensorflow BatchNormalization calculates mean and variances\n",
    "# Accoring to gpt it computes mean and variance across channels, so let's do that\n",
    "\n",
    "# below will calculate means for each channel. given tensor (10,5,5,5) for each channel total of 10*5*5=250 datapoints and we take mean across them\n",
    "mean=tf.reduce_mean(tf_out,axis=[0,1,2])\n",
    "var=tf.math.reduce_variance(tf_out,axis=[0,1,2])\n",
    "\n",
    "print(f\"manual mean : {mean}, manual variance : {var}\")\n",
    "print(f\"tf bn mean : {bn_model.layers[1].moving_mean}, tf bn variance : {bn_model.layers[1].moving_variance}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 5, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "x_torch = torch.tensor(tf_out.numpy()).permute(0,3,1,2)\n",
    "torch_batch_norm = nn.BatchNorm2d(num_features=5, affine=False)\n",
    "torch_batch_norm.train()\n",
    "torch_bn_out = torch_batch_norm(x_torch)\n",
    "print(torch_bn_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<tf.Variable 'batch_normalization/moving_mean:0' shape=(5,) dtype=float32, numpy=array([0., 0., 0., 0., 0.], dtype=float32)>\n",
      "<tf.Variable 'batch_normalization/moving_variance:0' shape=(5,) dtype=float32, numpy=array([1., 1., 1., 1., 1.], dtype=float32)>\n"
     ]
    }
   ],
   "source": [
    "print(bn_model.layers[1].moving_mean)\n",
    "print(bn_model.layers[1].moving_variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BatchNorm2d output first sample across channels tensor([0.1604, 0.2819, 0.0793, 0.0826, 0.4031])\n",
      "BatchNorm2d output first sample across last dim tensor([-1.7095, -0.7310,  0.2003, -0.8787,  1.3037])\n",
      "tf bn output : [0.16030471 0.28168422 0.07928884 0.08257569 0.40281639]\n",
      "x_torch first sample across channels :  tensor([0.0978, 0.1913, 0.1848, 0.0489, 0.3986])\n",
      "tf_out across channels :  tf.Tensor([0.09782689 0.19126739 0.18478946 0.04893163 0.39858615], shape=(5,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(\"BatchNorm2d output first sample across channels\",torch_bn_out[0,:,0,2])\n",
    "print(\"BatchNorm2d output first sample across last dim\",torch_bn_out[0,0,2,:])\n",
    "print(f\"tf bn output : {tf_bn_out[0,0,2,:]}\")\n",
    "print(\"x_torch first sample across channels : \",x_torch[0,:,0,2])\n",
    "print(\"tf_out across channels : \",tf_out[0,0,2,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average Pooling behaviour"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(10,32,64,64)\n",
    "out=nn.AvgPool2d(kernel_size=2)(x)\n",
    "print(\"nn.AvgPool2d output when applied to x with shape (10,32,64,64): \",out.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's compare output of Residual Blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def copy_tf_conv_weights_to_torch_conv(tf_conv,torch_conv):\n",
    "    tf_conv_filters=tf_conv.get_weights()[0]\n",
    "    tf_conv_filters_bias = tf_conv.get_weights()[1]\n",
    "\n",
    "    # I want to manually set the parameters of nn.Conv2D\n",
    "    tc_filters = torch.from_numpy(tf_conv_filters)\n",
    "    tc_filters = tc_filters.permute(3,2,0,1)\n",
    "    tc_filt_biases = torch.from_numpy(tf_conv_filters_bias)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        torch_conv.weight.copy_(tc_filters)\n",
    "        torch_conv.bias.copy_(tc_filt_biases)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "width=10\n",
    "tf_conv_one = layers.Conv2D(width, kernel_size=1)\n",
    "tf_conv_two = layers.Conv2D(\n",
    "            width, kernel_size=3, padding=\"same\", activation=activations.swish\n",
    "        )\n",
    "tf_conv_three = layers.Conv2D(width, kernel_size=3, padding=\"same\")\n",
    "tf_bn = layers.BatchNormalization(center=False, scale=False)\n",
    "\n",
    "def TfResidualBlock():\n",
    "    def apply(x):\n",
    "        input_width = x.shape[3]\n",
    "        if input_width == width:\n",
    "            residual = x\n",
    "        else:\n",
    "            residual = tf_conv_one(x)\n",
    "        x = tf_bn(x, training=True)\n",
    "        x = tf_conv_two(x)\n",
    "        x = tf_conv_three(x)\n",
    "        x = layers.Add()([x, residual])\n",
    "        return x\n",
    "\n",
    "    return apply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf res output : (10, 5, 5, 10)\n"
     ]
    }
   ],
   "source": [
    "tf_x = tf_out\n",
    "tf_res_out = TfResidualBlock()(tf_x)\n",
    "print(f\"tf res output : {tf_res_out.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "# let's define torch ResidualBlock\n",
    "in_channels = 5\n",
    "out_channels = 10\n",
    "\n",
    "class Swish(nn.Module):\n",
    "    def forward(self, x):\n",
    "        return x * torch.sigmoid(x)\n",
    "\n",
    "tc_conv_shortcut=nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "copy_tf_conv_weights_to_torch_conv(tf_conv_one,tc_conv_shortcut)\n",
    "\n",
    "tc_conv1 = nn.Conv2d(in_channels=in_channels,out_channels=out_channels, kernel_size=3, padding=1, stride=1)\n",
    "copy_tf_conv_weights_to_torch_conv(tf_conv_two,tc_conv1)\n",
    "\n",
    "tc_conv2 = nn.Conv2d(in_channels=out_channels, out_channels=out_channels, kernel_size=3, padding=1, stride=1)\n",
    "copy_tf_conv_weights_to_torch_conv(tf_conv_three, tc_conv2)\n",
    "\n",
    "class TcResidualBlock(nn.Module):\n",
    "    def __init__(self, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)        \n",
    "        if in_channels!=out_channels:\n",
    "            self.shortcut = tc_conv_shortcut\n",
    "        else:\n",
    "            self.shortcut = nn.Identity()        \n",
    "        self.batch_norm = nn.BatchNorm2d(num_features=in_channels,affine=False)\n",
    "        self.conv1 = tc_conv1\n",
    "        self.swish = Swish()\n",
    "        self.conv2 = tc_conv2\n",
    "\n",
    "    \n",
    "    def forward(self,x):        \n",
    "        residual = self.shortcut(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.conv1(x)\n",
    "        x = self.swish(x)\n",
    "        x = self.conv2(x)\n",
    "        return x + residual\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "torch_x = torch.tensor(tf_x.numpy())\n",
    "torch_x = torch_x.permute(0,3,1,2)\n",
    "\n",
    "tc_res_block=TcResidualBlock()\n",
    "tc_res_block.train()\n",
    "tc_out = tc_res_block(torch_x)\n",
    "print(tc_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf out first channel : [-0.56412524 -0.37567738 -1.1697795   1.0911057  -0.01003164  0.401801\n",
      "  0.58847225  0.50728196 -0.19187619 -0.267038  ]\n",
      "tc out first channel : tensor([-0.5645, -0.3761, -1.1700,  1.0914, -0.0104,  0.4017,  0.5884,  0.5072,\n",
      "        -0.1920, -0.2670], grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"tf out first channel : {tf_res_out[0,0,0,:]}\")\n",
    "print(f\"tc out first channel : {tc_out[0,:,0,0]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_311_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
