{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pathlib\n",
    "\n",
    "sys.path.append(r\"C:\\Users\\amrul\\programming\\deep_learning\\dl_projects\\Generative_Deep_Learning_2nd_Edition\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "\n",
    "IMAGE_SIZE = 64\n",
    "BATCH_SIZE = 64\n",
    "DATASET_REPETITIONS = 5\n",
    "LOAD_MODEL = False\n",
    "\n",
    "NOISE_EMBEDDING_SIZE = 32\n",
    "PLOT_DIFFUSION_STEPS = 20\n",
    "\n",
    "# optimization\n",
    "EMA = 0.999\n",
    "LEARNING_RATE = 1e-3\n",
    "WEIGHT_DECAY = 1e-4\n",
    "EPOCHS = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "class SinusoidalPosEmb(nn.Module):\n",
    "    def __init__(self, dim, theta=10000):\n",
    "        super().__init__()\n",
    "        self.dim = dim\n",
    "        self.theta = theta\n",
    "\n",
    "    def forward(self, x):\n",
    "        device = x.device\n",
    "        half_dim = self.dim // 2\n",
    "        emb = math.log(self.theta) / (half_dim - 1)\n",
    "        emb = torch.exp(torch.arange(half_dim, device=device) * -emb)\n",
    "        # emb = x[:, None] * emb[None, :]\n",
    "        emb = x*emb\n",
    "        emb = torch.cat((emb.sin(), emb.cos()), dim=-1)\n",
    "        return emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "sin_emb = SinusoidalPosEmb(32,1000)\n",
    "x = torch.tensor([0.34])\n",
    "emb = sin_emb(x)\n",
    "print(emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.3349e-01, 2.1288e-01, 1.3494e-01, 8.5300e-02, 5.3860e-02, 3.3993e-02,\n",
       "         2.1451e-02, 1.3535e-02, 8.5403e-03, 5.3886e-03, 3.4000e-03, 2.1453e-03,\n",
       "         1.3536e-03, 8.5404e-04, 5.3886e-04, 3.4000e-04, 9.4275e-01, 9.7708e-01,\n",
       "         9.9085e-01, 9.9636e-01, 9.9855e-01, 9.9942e-01, 9.9977e-01, 9.9991e-01,\n",
       "         9.9996e-01, 9.9999e-01, 9.9999e-01, 1.0000e+00, 1.0000e+00, 1.0000e+00,\n",
       "         1.0000e+00, 1.0000e+00]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SinusoidalEmbedding(nn.Module):\n",
    "    def __init__(self, device, *args, **kwargs) -> None:\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.device = device\n",
    "        thefreq = torch.log(torch.tensor(1000.0)/15)\n",
    "        # frequencies = torch.linspace(torch.log(torch.tensor(1.0)),torch.log(torch.tensor(1000.0)),16)        \n",
    "        frequencies = torch.arange(16) * -thefreq\n",
    "        frequencies = frequencies.to(device)\n",
    "        self.frequencies = frequencies\n",
    "    \n",
    "    def forward(self,x):\n",
    "        angular_speeds = 2 * torch.pi * torch.exp(self.frequencies) * x\n",
    "        # return single scalar as 32 dimensional vector\n",
    "        return torch.cat((torch.sin(angular_speeds),torch.cos(angular_speeds)),dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32])\n"
     ]
    }
   ],
   "source": [
    "mysin_emb = SinusoidalEmbedding(x.device)\n",
    "my_emb = mysin_emb(x)\n",
    "print(my_emb.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 8.4433e-01,  3.2039e-02,  4.8066e-04,  7.2100e-06,  1.0815e-07,\n",
       "         1.6222e-09,  2.4334e-11,  3.6500e-13,  5.4751e-15,  8.2126e-17,\n",
       "         1.2319e-18,  1.8478e-20,  2.7717e-22,  4.1576e-24,  6.2364e-26,\n",
       "         9.3547e-28, -5.3583e-01,  9.9949e-01,  1.0000e+00,  1.0000e+00,\n",
       "         1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "         1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,  1.0000e+00,\n",
       "         1.0000e+00,  1.0000e+00])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_emb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_311_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
