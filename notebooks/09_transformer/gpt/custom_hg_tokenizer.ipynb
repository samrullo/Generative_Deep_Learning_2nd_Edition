{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's load wine reviews dataset with load_dataset from datasets library of HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import pathlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE = 10000\n",
    "MAX_LEN = 80\n",
    "EMBEDDING_DIM = 256\n",
    "KEY_DIM = 256\n",
    "N_HEADS = 2\n",
    "FEED_FORWARD_DIM = 256\n",
    "VALIDATION_SPLIT = 0.2\n",
    "SEED = 42\n",
    "LOAD_MODEL = False\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 5\n",
    "UNKOWN_WORD = \"<unk>\"\n",
    "PAD_TOKEN = \"<pad>\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the full dataset\n",
    "datasets_folder = pathlib.Path(r\"C:\\Users\\amrul\\programming\\deep_learning\\dl_projects\\Generative_Deep_Learning_2nd_Edition\\data\")\n",
    "wine_review_filepath=datasets_folder/\"wine_reviews\"/\"winemag-data-130k-v2.json\"\n",
    "data = load_dataset(str(wine_review_filepath.parent),'json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_text_with_country_variety(batch):\n",
    "    text_with_country_variety = [f\"{country} : {province} : {variety} : {description}\" for country, province, variety, description in zip(batch['country'],batch['province'], batch['variety'], batch['description'])]\n",
    "    return {\"text\": text_with_country_variety}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_ds = data.map(prepare_text_with_country_variety,batched=True, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_reviews = wine_ds[\"train\"][\"text\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's build custom tokenizer\n",
    "This tokenizer will split text on whitespace and punctuation marks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_tokenize(text):\n",
    "    return re.findall(r\"\\w+|[^\\w\\s]\",text,re.UNICODE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Italy', ':', 'Sicily', '&', 'Sardinia', ':', 'White', 'Blend', ':', 'Aromas', 'include', 'tropical', 'fruit', ',', 'broom', ',', 'brimstone', 'and', 'dried', 'herb', '.', 'The', 'palate', 'isn', \"'\", 't', 'overly', 'expressive', ',', 'offering', 'unripened', 'apple', ',', 'citrus', 'and', 'dried', 'sage', 'alongside', 'brisk', 'acidity', '.']\n"
     ]
    }
   ],
   "source": [
    "tokens=custom_tokenize(wine_reviews[0])\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build a vocabulary\n",
    "\n",
    "tokenized_wine_reviews = [custom_tokenize(text) for text in wine_reviews]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_review_tokens = [token for tokenized_text in tokenized_wine_reviews for token in tokenized_text]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "wine_review_token_counter = Counter(wine_review_tokens)\n",
    "wine_review_vocab_words = wine_review_token_counter.most_common(VOCAB_SIZE)\n",
    "\n",
    "wr_word_to_id = { word:idx for idx, (word,_) in enumerate(wine_review_vocab_words)}\n",
    "\n",
    "wr_word_to_id[UNKOWN_WORD] = len(wr_word_to_id)\n",
    "wr_word_to_id[PAD_TOKEN] = len(wr_word_to_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "wr_id_to_word = {id:word for word, id in wr_word_to_id.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enhanced_tokenize(text, word_to_id):\n",
    "    tokens = custom_tokenize(text)\n",
    "    return [token if token in word_to_id else UNKOWN_WORD for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_convert_to_ids(text, word_to_id):\n",
    "    tokens = enhanced_tokenize(text,word_to_id)\n",
    "    return [wr_word_to_id[token] for token in tokens]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 : Italy\n",
      "1 : :\n",
      "445 : Sicily\n",
      "447 : &\n",
      "469 : Sardinia\n",
      "1 : :\n",
      "165 : White\n",
      "36 : Blend\n",
      "1 : :\n",
      "214 : Aromas\n",
      "980 : include\n",
      "249 : tropical\n",
      "19 : fruit\n",
      "0 : ,\n",
      "2301 : broom\n",
      "0 : ,\n",
      "4091 : brimstone\n",
      "3 : and\n",
      "117 : dried\n",
      "131 : herb\n",
      "2 : .\n",
      "17 : The\n",
      "25 : palate\n",
      "1019 : isn\n",
      "14 : '\n",
      "233 : t\n",
      "1174 : overly\n",
      "1069 : expressive\n",
      "0 : ,\n",
      "356 : offering\n",
      "10000 : <unk>\n",
      "71 : apple\n",
      "0 : ,\n",
      "81 : citrus\n",
      "3 : and\n",
      "117 : dried\n",
      "482 : sage\n",
      "162 : alongside\n",
      "457 : brisk\n",
      "29 : acidity\n",
      "2 : .\n"
     ]
    }
   ],
   "source": [
    "input_ids = tokenize_and_convert_to_ids(wine_reviews[0],wr_word_to_id)\n",
    "for id in input_ids:\n",
    "    print(f\"{id} : {wr_id_to_word[id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_tokenize(example):\n",
    "    \"\"\"\n",
    "    example will represent one element from Dataset batch\n",
    "    \"\"\"\n",
    "    input_ids = tokenize_and_convert_to_ids(example[\"text\"],wr_word_to_id)\n",
    "    if len(input_ids) > MAX_LEN+1:\n",
    "        return {\"input_ids\":input_ids[:MAX_LEN+1]}\n",
    "    else:\n",
    "        input_ids = input_ids + [wr_word_to_id[PAD_TOKEN]]*(MAX_LEN+1-len(input_ids))\n",
    "        # for idx in range(len(input_ids),MAX_LEN+1):\n",
    "        #     input_ids.append(wr_word_to_id[PAD_TOKEN])\n",
    "        return {\"input_ids\":input_ids}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_ds2 = wine_ds.map(batch_tokenize, batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "129971\n"
     ]
    }
   ],
   "source": [
    "input_ids=wine_ds2[\"train\"][\"input_ids\"]\n",
    "print(len(input_ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input ids with maximum length : 81\n"
     ]
    }
   ],
   "source": [
    "input_ids_lengthes = [len(input_id_list) for input_id_list in input_ids]\n",
    "print(f\"input ids with maximum length : {max(input_ids_lengthes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([81], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# let's confirm that all input_ids have the same length\n",
    "import pandas as pd\n",
    "pd.Series(input_ids_lengthes).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38 : Italy\n",
      "1 : :\n",
      "445 : Sicily\n",
      "447 : &\n",
      "469 : Sardinia\n",
      "1 : :\n",
      "165 : White\n",
      "36 : Blend\n",
      "1 : :\n",
      "214 : Aromas\n",
      "980 : include\n",
      "249 : tropical\n",
      "19 : fruit\n",
      "0 : ,\n",
      "2301 : broom\n",
      "0 : ,\n",
      "4091 : brimstone\n",
      "3 : and\n",
      "117 : dried\n",
      "131 : herb\n",
      "2 : .\n",
      "17 : The\n",
      "25 : palate\n",
      "1019 : isn\n",
      "14 : '\n",
      "233 : t\n",
      "1174 : overly\n",
      "1069 : expressive\n",
      "0 : ,\n",
      "356 : offering\n",
      "10000 : <unk>\n",
      "71 : apple\n",
      "0 : ,\n",
      "81 : citrus\n",
      "3 : and\n",
      "117 : dried\n",
      "482 : sage\n",
      "162 : alongside\n",
      "457 : brisk\n",
      "29 : acidity\n",
      "2 : .\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n",
      "10001 : <pad>\n"
     ]
    }
   ],
   "source": [
    "for id in input_ids[0]:\n",
    "    print(f\"{id} : {wr_id_to_word[id]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_id_to_tensor(example):\n",
    "    return {\"input_ids_pt\":torch.tensor(example[\"input_ids\"])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_ds3 = wine_ds2.map(input_id_to_tensor,batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_ids tensor shape : torch.Size([129971, 81])\n"
     ]
    }
   ],
   "source": [
    "input_ids_tensor = torch.cat([torch.tensor(input_ids_record).unsqueeze(0) for input_ids_record in input_ids],dim=0)\n",
    "print(f\"input_ids tensor shape : {input_ids_tensor.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = input_ids_tensor[:,:80],input_ids_tensor[:,1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x shape : torch.Size([129971, 80]), y shape : torch.Size([129971, 80])\n"
     ]
    }
   ],
   "source": [
    "print(f\"x shape : {x.size()}, y shape : {y.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "\n",
    "class WineReviewDataset(Dataset):\n",
    "    def __init__(self, x, y) -> None:\n",
    "        super().__init__()\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.x.size(0)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        return self.x[idx], self.y[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "onex shape : torch.Size([80])\n"
     ]
    }
   ],
   "source": [
    "twine_ds = WineReviewDataset(x,y)\n",
    "one_x, one_y=twine_ds[100]\n",
    "print(f\"onex shape : {one_x.size()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "wine_loader = DataLoader(twine_ds,batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_x shape : torch.Size([32, 80]), batch_y shape torch.Size([32, 80])\n",
      "batch_x shape : torch.Size([32, 80]), batch_y shape torch.Size([32, 80])\n",
      "batch_x shape : torch.Size([32, 80]), batch_y shape torch.Size([32, 80])\n",
      "batch_x shape : torch.Size([32, 80]), batch_y shape torch.Size([32, 80])\n",
      "batch_x shape : torch.Size([32, 80]), batch_y shape torch.Size([32, 80])\n",
      "batch_x shape : torch.Size([32, 80]), batch_y shape torch.Size([32, 80])\n",
      "batch_x shape : torch.Size([32, 80]), batch_y shape torch.Size([32, 80])\n"
     ]
    }
   ],
   "source": [
    "for idx, (batch_x, batch_y) in enumerate(wine_loader):\n",
    "    print(f\"batch_x shape : {batch_x.size()}, batch_y shape {batch_y.size()}\")\n",
    "    if idx>5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 5, 5])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tril(torch.ones(5,5)).unsqueeze(0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "query=key=value=torch.rand(5,2).unsqueeze(0)\n",
    "scores = torch.bmm(query,key.transpose(1,2))\n",
    "print(scores.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.1421,   -inf,   -inf,   -inf,   -inf],\n",
       "         [0.2509, 0.6434,   -inf,   -inf,   -inf],\n",
       "         [0.3876, 0.5177, 1.1969,   -inf,   -inf],\n",
       "         [0.3457, 0.4763, 1.0552, 0.9312,   -inf],\n",
       "         [0.3212, 0.6456, 0.8112, 0.7292, 0.7569]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask=torch.tril(torch.ones(5,5)).unsqueeze(0)\n",
    "scores.masked_fill(mask==0,-float(\"inf\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's implement Token and Positional embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class TokenPositionEmbedding(nn.Module):\n",
    "    def __init__(self,vocab_size, max_len,embed_dim):\n",
    "        super(TokenPositionEmbedding,self).__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.max_len = max_len\n",
    "        self.embed_dim = embed_dim\n",
    "        self.embedding = nn.Embedding(self.vocab_size,self.embed_dim)\n",
    "        self.pos_embedding = nn.Embedding(self.max_len, self.embed_dim)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        # x is (N,L) tensor where each row is a list of token IDs\n",
    "        positions = torch.arange(self.max_len)\n",
    "        positions_embeddings = self.pos_embedding(positions)\n",
    "        return self.embedding(x) + positions_embeddings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "VOCAB_SIZE=len(wr_word_to_id)\n",
    "seq_len=80\n",
    "embed_dim=100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "token_pos_embed = TokenPositionEmbedding(VOCAB_SIZE,seq_len,embed_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_embedded = token_pos_embed(batch_x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 80, 100])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_embedded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# first argument is embedding dimension which is 100 in our case, second argument is the number of attention heads which is 4 in our case\n",
    "# MultiheadAttention will project query,key and value vectors to embed_dim/num_heads dimension and apply attention separately\n",
    "# remember scaled dot product between query and key produces scores, which are passed through softmax to normalized and then weighted product of values is the output of representation of the token\n",
    "# this is done num_heads times and representations of each tokens from each head is horizontally concatenated\n",
    "multihead = nn.MultiheadAttention(embed_dim,4,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we can use this as input to attn_mask argument of MultiHeadAttention when calling it\n",
    "# as you can see we are first using torch.tril to generate square matrix where values above diagonal are zero\n",
    "# then we set elements where values are zero to True, indicating those are the positions that we want to mask\n",
    "mask = torch.tril(torch.ones(seq_len, seq_len))==0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "attn_out, attn_weights = multihead(one_embedded,one_embedded,one_embedded,attn_mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 80, 80])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attn_weights.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "layer_norm = nn.LayerNorm(normalized_shape=embed_dim,eps=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = layer_norm(attn_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attention output first ten elements : tensor([-0.2083,  1.0783, -0.4119,  0.8707,  0.5460, -0.7446,  0.2810,  0.5366,\n",
      "        -0.2513,  0.4071], grad_fn=<SliceBackward0>)\n",
      "layer norm output first ten elements : tensor([-0.4388,  1.9099, -0.8106,  1.5308,  0.9382, -1.4179,  0.4544,  0.9209,\n",
      "        -0.5173,  0.6845], grad_fn=<SliceBackward0>)\n",
      "mean of first element : tensor([-2.8610e-08,  2.1458e-08, -2.3842e-09,  2.9802e-08,  1.7881e-08,\n",
      "        -3.5763e-09, -4.7684e-09,  4.7684e-09,  9.5367e-09,  3.8147e-08],\n",
      "       grad_fn=<SliceBackward0>), std of first element : tensor([1.0050, 1.0050, 1.0050, 1.0050, 1.0050, 1.0050, 1.0050, 1.0050, 1.0050,\n",
      "        1.0050], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "print(f\"attention output first ten elements : {attn_out[0,0,:10]}\")\n",
    "print(f\"layer norm output first ten elements : {out[0,0,:10]}\")\n",
    "print(f\"mean of first element : {out[0,:].mean(axis=1)[:10]}, std of first element : {out[0,:].std(axis=1)[:10]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_311_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
